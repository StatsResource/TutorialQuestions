
\newpage

\item A confusion matrix is a table that is often used to describe the performance of a binary classification procedure on a set of test data for which the true values are known.
\begin{center}
\begin{tabular}{|c|c|c|}
\hline  & Predicted Negative & Predicted Positive \\ 
\hline Observed Negative & True Negative & False Positive \\ 
\hline Observed Positive & False Negative & True Positive \\ 
\hline 
\end{tabular} 
\end{center}
\begin{enumerate}[(i)]



\item Define each of the following appraisal metrics for binary classification:
\begin{enumerate}[(i)]
    \item (1 Mark) Accuracy,
    \item (1 Mark) Precision,
    \item (1 Mark) Recall.
    \end{enumerate}

\item (2 Marks) What is the F-measure? Explain its function and how it is computed.\\ 
\noindent \textit{ Hint: F-score = $(2 \times P \times R) / (P + R)$.}
%\item[iii.](2 Marks) Define Specificity and Sensitivity. You make reference to previous answers.
%\item[iv.](3 Marks) What is a ROC curve? Explain its function, how it is determined, and the means of interpreting the curve. Support your answer with a sketch.
\end{enumerate}


% \item %  Binary Classification (4 Marks)
% For the confusion matrix below, calculate the following appraisal metrics.
%
%	\begin{enumerate}[(i)]
%		\item (1 Mark) Accuracy,
%		\item (1 Mark) Recall,
%		\item (1 Mark) Precision,
%		\item (1 Mark) F-score.
%	\end{enumerate}
%
%
% \begin{center}
%	
%	\begin{tabular}{|c||c|c|}
%		\hline 
%		& Predict Negative & Predict Positive \\ \hline  \hline 
%		Observed Negative & 9300 &  100 \\ \hline 
%		Observed Positive & 200 & 400 \\ \hline 
% 	\end{tabular} 
% \end{center}

\medskip


\end{enumerate}
\end{document}